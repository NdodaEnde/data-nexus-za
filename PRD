# South African Evidence & Insights Platform (MVP)

## Product Overview
South African Evidence & Insights Platform (MVP) is a federated, open-data web application that ingests, harmonises and visualises South African socio-economic datasets at ward-level granularity. It provides interactive maps, charts and scrolly-telling stories that expose performance gaps versus peer-country KPI trajectories and surface evidence-based policy levers with transparent data provenance and quality indicators.

## User Stories (Gherkin) - Enhanced

### Core Public Access
**US-01** As a Public User, I want to open the homepage without an account so that I can immediately see the latest data stories.

**US-02** As a Public User, I want to type "youth unemployment in KwaZulu-Natal" in the Ask-Data bar so that I receive an auto-generated chart within 2 seconds.

**US-03** As a Public User, I want to click a ward on the map so that I see granular indicators for that ward.

**US-NEW-01** As a Public User, I want to see data freshness indicators on every chart so that I know if I'm looking at current or stale data.

**US-NEW-02** As a Public User, I want to bookmark specific views so that I can return to them later.

**US-NEW-03** As a Public User, I want to see confidence intervals on projections so that I understand data uncertainty.

### Professional Users
**US-04** As a Policy Analyst, I want to compare SA youth unemployment to South Korea's 2027 target so that I can set realistic departmental KPIs.

**US-05** As a Policy Analyst, I want to export a Gap-Lens view as PNG so that I can embed it in a presentation.

**US-NEW-04** As a Policy Analyst, I want to generate properly formatted citations for datasets so that I can reference them in reports.

**US-NEW-05** As a Policy Analyst, I want to set up alerts when key indicators change significantly so that I can respond quickly.

### Content Creation
**US-06** As a Journalist, I want to create a scrolly-story without coding so that I can publish it on my news site via iframe.

**US-07** As a Journalist, I want to preview my scrolly-story on mobile and desktop before publishing.

**US-NEW-06** As a Journalist, I want fact-checking warnings when my story contradicts official data so that I maintain accuracy.

**US-NEW-07** As a Journalist, I want to see story analytics (views, shares) so that I can measure impact.

### Research & Development
**US-08** As an NGO Researcher, I want to download ward-level CSV so that I can run further regressions offline.

**US-09** As an NGO Researcher, I want to filter data by "rural" vs "urban" classification so that I can focus my study.

**US-NEW-08** As an NGO Researcher, I want to see methodology documentation for every dataset so that I understand collection methods.

**US-NEW-09** As an NGO Researcher, I want to request specific datasets not yet in the platform so that I can influence the roadmap.

### API & Integration
**US-10** As a Private Sector User, I want to register for an API key so that I can query indicators programmatically.

**US-11** As a Private Sector User, I want rate-limit information in the API response headers so that I can manage my quota.

**US-NEW-10** As a Private Sector User, I want webhook notifications when key datasets update so that my systems stay current.

### Operations & Governance
**US-12** As a System Admin, I want to trigger an Airbyte sync from Stats SA so that the latest QLFS is ingested.

**US-13** As a System Admin, I want to see an ETL health dashboard so that I can detect pipeline failures.

**US-NEW-11** As a System Admin, I want automated data quality reports so that I can catch anomalies before publication.

**US-NEW-12** As a Content Moderator, I want to review flagged stories before publication so that I can prevent misinformation.

**US-14** As a Security Officer, I want PII redaction logs so that I can audit compliance with POPIA.

**US-15** As a DevOps Engineer, I want blue-green deployments so that releases cause zero downtime.

### Testing & Quality
**US-16** As a Tester, I want synthetic ward data so that I can run automated UI tests without touching production.

**US-17** As a Tester, I want visual regression tests on the Gap-Lens screen so that chart colours remain consistent.

**US-NEW-13** As a Tester, I want LLM query regression tests so that natural language parsing remains accurate.

### Maintenance & Reliability
**US-18** As a Maintainer, I want dependency-vulnerability scanning on each PR so that we catch CVEs early.

**US-19** As a Maintainer, I want automated daily backups of the DuckDB warehouse so that recovery time <15 min.

**US-20** As a Maintainer, I want to scale vector tile generation horizontally via Kubernetes Jobs when new boundaries arrive.

**US-NEW-14** As a Maintainer, I want graceful degradation when ward boundaries update so that existing bookmarks remain functional.

## Enhanced Data Ingestion Strategy

### Multi-Modal Ingestion Pipeline
- **Structured Data**: Airbyte connectors for APIs, CSV, Excel
- **PDF Processing**: 
  - OCR pipeline (Tesseract) for scanned documents
  - Table extraction (pdfplumber, Camelot) for digital PDFs
  - Human-in-the-loop validation for critical datasets
- **Inconsistent APIs**: 
  - Schema evolution tracking in dbt
  - Fallback to manual ingestion with alerts
  - API reliability scoring and auto-retry logic
- **Data Quality Gates**:
  - Great Expectations validation before warehouse load
  - Anomaly detection using statistical bounds
  - Source reliability scoring (freshness, consistency, completeness)

## Enhanced Content Moderation Framework

### Story Quality Assurance
- **Automated Fact-Checking**:
  - Cross-reference story claims against verified datasets
  - Flag statistical inconsistencies (e.g., percentages >100%)
  - Highlight unsupported trend assertions
- **Human Review Process**:
  - Queue flagged stories for moderation
  - Expert reviewer assignment by domain (health, education, etc.)
  - Version control for editorial changes
- **Community Governance**:
  - User reporting system for questionable content
  - Transparent moderation logs
  - Appeals process for removed content

## Technical Architecture - Enhanced

### Core Stack (Unchanged)
- **Front-end**: Next.js 14 (App Router, TypeScript)
- **API Layer**: FastAPI (Python) behind Cloudflare CDN
- **Data Warehouse**: DuckDB (local) → Snowflake (future)
- **Tile Service**: MinIO + TileServer-GL behind CloudFront
- **ETL**: Airbyte + dbt Core + Kestra scheduler
- **Auth**: NextAuth.js (JWT, 15 min expiry)

### Enhanced Components

#### Geospatial Architecture
```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│ DuckDB-WASM     │    │ PostGIS Service  │    │ Vector Tiles    │
│ (Aggregations)  │    │ (Spatial Joins)  │    │ (Map Rendering) │
└─────────────────┘    └──────────────────┘    └─────────────────┘
        │                        │                        │
        └────────────────────────┼────────────────────────┘
                                 │
                    ┌──────────────────┐
                    │ Tile Generation  │
                    │ (K8s Jobs)       │
                    └──────────────────┘
```

#### LLM Query Pipeline
```
User Query → Template Matching → Schema Generation → SQL Execution → Chart Config
     │              │                    │                │              │
     │         [4 Templates]        [JSON Schema]    [DuckDB/PostGIS]  [Observable Plot]
     │              │                    │                │              │
     └─── Fallback: "Query not supported" if no template match ────────┘
```

#### Data Provenance System
```
┌─────────────┐    ┌─────────────────┐    ┌─────────────────┐
│ Source      │───▶│ Lineage Tracker │───▶│ UI Footer       │
│ Metadata    │    │ (dbt docs)      │    │ Component       │
└─────────────┘    └─────────────────┘    └─────────────────┘
```

## API Specifications - Enhanced

### Core Endpoints (Unchanged)
```
GET /api/v1/wards?province=KZN
GET /api/v1/indicators?metric=youth_unemployment&year=2023
POST /api/v1/query { "natural": "show heatmap of clinic density vs matric pass" }
GET /api/v1/export?indicators=x,y&format=csv&ward=all
GET /api/v1/tiles/{z}/{x}/{y}.pbf
```

### New Endpoints
```
GET /api/v1/data-quality?indicator=youth_unemployment
GET /api/v1/provenance?dataset_id=qlfs_2023_q4
POST /api/v1/bookmarks { "view_config": {...}, "name": "KZN Education" }
GET /api/v1/alerts?user_id=123
POST /api/v1/stories/fact-check { "story_id": 456 }
GET /spatial/v1/overlays?ward_geojson={...}&layer=schools
```

### Enhanced Rate Limits
- **Public**: 60 req/min, 1000 req/day
- **Authenticated**: 600 req/min, 50K req/day  
- **API Partners**: 6000 req/min, 1M req/day
- **Heavy Query Protection**: Complex spatial queries limited to 10/min per user

## Data Quality & Freshness Framework

### Quality Indicators
- **Completeness**: % of expected records present
- **Freshness**: Days since last update vs. expected frequency  
- **Consistency**: Cross-dataset validation scores
- **Accuracy**: Expert review confidence ratings

### UI Quality Signals
```jsx
// Every chart footer includes:

```

### Degraded Experience Handling
- **Stale Data**: Yellow warning banner "Data is X days old"
- **Incomplete Data**: Dotted chart lines with tooltips explaining gaps
- **Low Quality**: Red "⚠ Data quality concerns" with link to methodology
- **Missing Boundaries**: Graceful fallback to parent geography level

## LLM Query System - Constrained & Reliable

### Template-Only Approach
1. **"Show [indicator] in [place] vs [peer-country]"**
   - Maps to: Gap analysis chart component
   - Validation: All three entities must exist in knowledge base

2. **"Generate KPI card for [indicator]"**  
   - Maps to: Current value + trend + target comparison
   - Validation: Indicator must have recent data

3. **"Create Gap-Lens chart for [indicator]"**
   - Maps to: Multi-scenario projection visualization
   - Validation: Indicator must have benchmark data

4. **"Explain this chart in plain language"**
   - Maps to: Context-aware narrative generation
   - Validation: Chart must be from approved templates

### Fallback Strategy
- **95% Coverage Target**: 19 out of 20 queries should match templates
- **Clear Rejection**: "This query type isn't supported yet. Try: [suggested templates]"
- **Usage Analytics**: Track failed queries to prioritize new templates
- **Escalation Path**: "Request this feature" link feeds product backlog

## Story Builder - Enhanced Templates

### Quick Templates
1. **"Quick Gap" Template**:
   ```markdown
   # [Auto: Indicator Name] in South Africa

   ## Current Situation
   [Auto-populated: Current KPI card]

   ## Global Comparison  
   [Auto-populated: SA vs peer countries chart]

   ## The Gap
   [Auto-populated: Gap analysis with targets]

   ## Policy Levers
   [Auto-populated: 3 evidence-based interventions]

   ## Call to Action
   [Template: Customizable conclusion paragraph]
   ```

2. **"Deep Dive" Template**: Province-level analysis with ward breakdowns
3. **"Time Series" Template**: Historical trends with projections
4. **"Cross-Sector" Template**: Multi-indicator correlation analysis

### Template Governance
- **Community Contributions**: OSS PRs for new templates
- **Quality Gates**: All templates must include data provenance requirements
- **Usage Analytics**: Track template popularity and completion rates

## Performance Requirements - Enhanced

### Core Metrics (Unchanged)
- P95 page load <2.5s on 4G
- P95 tile request <300ms  
- P95 complex query <4s (server) / <1s (cached)
- Lighthouse score ≥90 on desktop

### New Performance Targets
- **Ward-Level Granularity**: P95 response <800ms for single ward lookup
- **Spatial Overlay**: P95 response <500ms for 1000 ward polygons
- **LLM Query**: P95 response <2s from template match to chart render
- **Story Builder**: Auto-save every 5s, P95 save operation <200ms
- **Data Export**: Stream initiation <1s, progress updates every 10%

### Graceful Degradation
- **Slow Connections**: Progressive loading with skeleton screens
- **Large Datasets**: Pagination with "Load more" instead of infinite scroll  
- **Complex Queries**: Background processing with email notification for exports >50MB
- **Mobile Performance**: Simplified visualizations, optional detail layers

## Security Enhancements

### Enhanced POPIA Compliance
- **Data Minimization**: Ward-level aggregation minimum thresholds (n≥10)
- **Automated PII Detection**: Pattern matching + manual review for sensitive fields
- **Consent Management**: Clear data usage explanations for uploaded content
- **Right to Deletion**: User data purge workflows with audit trails

### Content Security
- **Story Sandboxing**: iframe isolation for embedded stories
- **XSS Prevention**: Content Security Policy for user-generated markdown
- **API Security**: Rate limiting + DDoS protection via Cloudflare
- **Dependency Security**: Automated vulnerability scanning with break-build policies

## Testing Strategy - Enhanced

### Core Testing (Unchanged)
- Unit: Jest (front), pytest (API)
- Integration: Playwright e2e suites (desktop + mobile)
- Visual regression: Percy on Gap-Lens & map screens
- Load testing: k6 targeting 500 concurrent users
- Security: OWASP ZAP scan in CI

### New Testing Components
- **LLM Query Testing**: Regression suite for template matching accuracy
- **Data Quality Testing**: Automated validation of ETL pipeline outputs  
- **Geospatial Testing**: Boundary update impact assessment
- **Story Template Testing**: Automated generation and validation of template outputs
- **API Contract Testing**: OpenAPI spec validation for all endpoints

## Deployment & Operations - Enhanced

### Core Deployment (Unchanged)
- Staging branch auto-deploys to Vercel preview
- Production release via GitHub release + tag triggers
- Blue-green on Fly.io; zero-downtime migrations
- Terraform scripts for infra (K8s, S3, CloudFront, RDS-PostGIS)

### Enhanced Operations
- **Monitoring**: Grafana + Prometheus + Loki + custom data quality dashboards
- **Alerting**: PagerDuty integration for critical data pipeline failures
- **Capacity Planning**: Auto-scaling based on query complexity, not just CPU
- **Disaster Recovery**: Cross-region backups with <15min RTO, <1hr RPO
- **Compliance Monitoring**: Automated POPIA audit trails and reporting

## Technical Addendum - Implementation Details

### Geospatial Trade-offs
- **MVP**: DuckDB-WASM for aggregations + PostGIS micro-service for spatial joins
- **PostGIS Endpoint**: `/spatial/v1/overlays` with <500ms SLA for 1K polygons
- **Future**: Evaluate DuckDB-Spatial extension once stable

### LLM Scope Control
- **Hard Template Limit**: Only 4 query types supported in MVP
- **Schema Generation**: LangChain returns deterministic JSON config
- **Failure Handling**: Clear error messages with suggested alternatives

### Data Provenance UI
- **Universal Requirement**: Every chart displays source footer
- **Missing Data Handling**: Red warning badge for unknown provenance
- **Metadata Pipeline**: Auto-population from dbt documentation

### Community Extensibility
- **Plugin Architecture**: Reserved namespace for future extensions
- **Governance**: All contributions must include data provenance
- **Documentation**: Clear plugin contract specification

---

This refined PRD addresses the core gaps while maintaining the excellent structure and ambition of the original. The key improvements focus on **reliability** (LLM constraints, error handling), **transparency** (data quality indicators), **completeness** (missing user stories), and **governance** (content moderation, community contributions).

**Next Steps - Implementation Roadmap**

**Phase 1: Foundation (Weeks 1-4)**
- Set up core infrastructure (Next.js, FastAPI, DuckDB, PostGIS)
- Implement basic data model and ETL pipeline for 2-3 key datasets
- Build essential UI components (maps, charts, navigation)
- Deploy MVP to staging environment

**Phase 2: Core Features (Weeks 5-8)**  
- Implement LLM query system with 4 constrained templates
- Build Gap-Lens visualization component
- Add data provenance footer system
- Implement basic story builder with Quick Gap template

**Phase 3: Quality & Polish (Weeks 9-12)**
- Add data quality indicators and freshness warnings
- Implement automated fact-checking for stories
- Build comprehensive testing suite
- Add performance monitoring and optimization

**Phase 4: Advanced Features (Weeks 13-16)**
- Scale to full ward-level granularity
- Add bookmark and alert systems
- Implement API rate limiting and webhooks  
- Launch community contribution framework

The refined PRD provides a solid foundation for building a world-class data platform that serves South Africa's strategic intelligence needs while maintaining technical excellence and user trust.

Let's start building Phase 1
